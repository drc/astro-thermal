---
import camera from "@/assets/camera.svg";
import cameraRotate from "@/assets/camera-rotate.svg";
import light from "@/assets/light.svg";
const ip = Astro.request.headers.get("x-forwarded-for");
const userAgent = Astro.request.headers.get("user-agent");
---

<main>
    <button id="torch">
        <img src={light.src} alt="Glyph of a lightbulb" />
    </button>
    <video playsinline muted autoplay></video>
    <canvas style="display: none;"></canvas>
    <input type="text" name="message" id="message" placeholder="Include a message" />
    <input type="text" name="ip" id="ip" value={ip} style="display: none;" />
    <input type="text" name="userAgent" id="userAgent" value={userAgent} style="display: none;" />
    <p id="printed" style="display: none;">Photo Printed!</p>
    <div>
        <button id="switch">
            <img src={cameraRotate.src} alt="Glyph of a camera with arrows indicating to switch the camera" />
        </button>
        <button id="snap"><img src={camera.src} alt="Glyph of a camera" /></button>
    </div>
</main>

<style>
    video {
        width: 100%;
        height: auto;
        max-height: 60vh;
        background-color: black;
        /* object-fit: cover; */
        border-radius: 20px;
    }

    #message {
        margin: 0 10%;
        font-size: 1.6rem;
        /* padding: 5px; */
    }
    main {
        /* height: 100vh; */
        max-width: 500px;
        display: flex;
        flex-direction: column;
        gap: 30px;
        margin: 0 auto;
        padding: 20px 0;
        position: relative;
    }
    div {
        display: flex;
        flex-direction: row;
        gap: 10px;
        justify-content: space-around;
        background-color: black;
        padding: 20px;
    }
    button {
        img {
            width: 45px;
            height: 50px;
        }
        border: none;
        width: 75px;
        height: 75px;
        display: flex;
        justify-content: center;
        align-items: center;
        height: auto;
        background-color: white;
        color: black;
        padding: 10px 20px;
        border-radius: 50px;
    }
    #snap {
        background-color: white;
        color: black;
    }
    #snap:disabled {
        background-color: grey;
        img {
            display: none;
        }
    }
    p#printed {
        font-family:
            system-ui,
            -apple-system,
            BlinkMacSystemFont,
            "Segoe UI",
            Roboto,
            Oxygen,
            Ubuntu,
            Cantarell,
            "Open Sans",
            "Helvetica Neue",
            sans-serif;
        text-align: center;
        font-size: 1.6rem;
        color: green;
    }
    button#torch {
        background-color: transparent;
        position: absolute;
        top: 20px;
        right: 20px;
        width: 30px;
        height: 30px;
    }
</style>

<script>
    import { actions } from "astro:actions";

    const constraints = {
        video: {
            width: { min: 512, ideal: 512, max: 512 },
            height: { min: 512, ideal: 512, max: 512 },
            facingMode: { ideal: "environment" },
        },
    };

    const videoRef = document.querySelector("video") as HTMLVideoElement;

    let stream = await navigator.mediaDevices.getUserMedia(constraints);
    if (videoRef) {
        const facingMode = stream.getVideoTracks()[0].getSettings().facingMode;
        if (facingMode === undefined) {
            videoRef.style.transform = "rotateY(180deg)";
        }
        videoRef.srcObject = stream;
        videoRef.play();
    }

    const switchButton = document.querySelector("button#switch") as HTMLButtonElement;
    switchButton.addEventListener("click", async () => {
        const facingMode = stream.getVideoTracks()[0].getSettings().facingMode;
        const tracks = stream.getVideoTracks();
        tracks[0].stop();

        stream = await navigator.mediaDevices.getUserMedia({
            video: { ...constraints.video, facingMode: facingMode === "user" ? "environment" : "user" },
        });
        videoRef.srcObject = stream;
        videoRef.play();
        videoRef.style.transform = "";
        if (facingMode !== "user") {
            videoRef.style.transform = "rotateY(180deg)";
        }
    });

    const torchButton = document.querySelector("button#torch") as HTMLButtonElement;
    torchButton.addEventListener("click", async () => {
        const tracks = stream.getVideoTracks();
        const track = tracks[0];
        const capabilities = track.getCapabilities();
        console.log(capabilities);
        if ((capabilities as any).torch) {
            const torchEnabled = (track.getConstraints() as any).advanced?.[0]?.torch ?? false;
            console.log(torchEnabled);
            await track.applyConstraints({ advanced: [{ torch: !torchEnabled }] } as any);
        }
    });

    const cameraButton = document.querySelector("button#snap") as HTMLButtonElement;
    cameraButton.addEventListener("click", async (e: MouseEvent) => {
        const canvasRef = document.querySelector("canvas") as HTMLCanvasElement;
        const context = canvasRef.getContext("2d", {
            willReadFrequently: true,
            alpha: false,
            desynchronized: true,
        }) as CanvasRenderingContext2D;
        const aspectRatio = (videoRef.videoWidth ?? 1) / (videoRef.videoHeight ?? 1);
        const width = videoRef.videoWidth ?? 600;
        const height = Math.floor((width / aspectRatio) * 8) / 8;
        canvasRef.width = width;
        canvasRef.height = height;

        context.drawImage(videoRef, 0, 0, width, height);

        const imageData = context.getImageData(0, 0, width, height) as ImageData;
        console.log(imageData);
        for (let i = 0; i < imageData.data.length; i += 4) {
            const brightness = (imageData.data[i] + imageData.data[i + 1] + imageData.data[i + 2]) / 2;
            imageData.data[i] = brightness;
            imageData.data[i + 1] = brightness;
            imageData.data[i + 2] = brightness;
        }

        context.putImageData(imageData, 0, 0);
        console.log();
        const imageDataUrl = canvasRef.toDataURL("image/png");
        const messageInput = document.querySelector("input#message") as HTMLInputElement;
        const ipInput = document.querySelector("input#ip") as HTMLInputElement;
        const userAgentInput = document.querySelector("input#userAgent") as HTMLInputElement;
        const { data: _data, error } = await actions.printPhoto({
            imageDataUrl,
            message: messageInput.value,
            ip_address: ipInput.value,
            user_agent: userAgentInput.value,
        });
        if (error) console.error(error);
        if (!error) {
            messageInput.value = "";
            const successMessage = document.querySelector("p#printed") as HTMLParagraphElement;
            successMessage.style.display = "block";
            cameraButton.disabled = true;
            videoRef.style.display = "none";
            canvasRef.style.display = "";
            setTimeout(() => {
                successMessage.style.display = "none";
                videoRef.style.display = "";
                canvasRef.style.display = "none";
                cameraButton.disabled = false;
            }, 3000);
        }
    });
</script>
